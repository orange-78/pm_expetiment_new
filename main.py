"""
é‡æ„åçš„ä¸»ç¨‹åº - main_refactored.py
"""

import json
import pickle
import sys
import argparse
from pathlib import Path
from typing import List, Optional
import os

from matplotlib import pyplot as plt
import numpy as np

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from config import DataConfig, ModelConfig, TrainingConfig
from data_pipeline import DataPipeline
from model_factory import ModelFactory
from trainer import TrainingPipeline, Trainer
from model_tester import ModelTester
from data_handler import DataManager
from visualizer import plot_grid_graph, plot_pm, plot_pm_with_history
from csv_data_manager import CSVDataManager
from model_runner import ModelRunner
from config import DATA_CONFIG, MODEL_CONFIG, TRAINING_CONFIG, load_config
from error_visualization import calculate_mae_by_step, calculate_mae_of_dataset, plot_mae_by_step


class ExperimentRunner:
    """å®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, 
                 data_config: Optional[DataConfig] = None,
                 model_config: Optional[ModelConfig] = None,
                 training_config: Optional[TrainingConfig] = None):
        
        self.data_config = data_config or DATA_CONFIG
        self.model_config = model_config or MODEL_CONFIG
        self.training_config = training_config or TRAINING_CONFIG
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_pipeline = DataPipeline(self.data_config)
        self.model_factory = ModelFactory()
        self.trainer = Trainer(self.training_config)
        self.training_pipeline = TrainingPipeline(
            self.data_pipeline, self.model_factory, self.trainer
        )
        self.model_tester = ModelTester(self.data_config)
    
    def single_experiment(self,
                         lookback: int,
                         steps: int,
                         model_name: str,
                         model_type: str = 'lstm_attention',
                         append_params: bool = True,
                         full_batch: bool = False) -> tuple:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        
        # æ„å»ºä¿å­˜åç§°
        if append_params:
            save_name = f"{model_name}-{lookback}_{steps}"
        else:
            save_name = model_name
        
        print(f"\n{'='*60}")
        print(f"Starting experiment: {save_name}")
        print(f"Lookback: {lookback}, Steps: {steps}")
        print(f"Model type: {model_type}")
        print(f"{'='*60}")
        
        # è¿è¡Œè®­ç»ƒ
        model, history, data_info = self.training_pipeline.run_training(
            model_type=model_type,
            lookback=lookback,
            steps=steps,
            model_config=self.model_config,
            save_name=save_name,
            full_batch=full_batch
        )
        
        print(f"Experiment {save_name} completed!")
        
        return model, history, data_info
    
    def batch_experiments(self,
                         lookbacks: List[int],
                         interval: int = 30,
                         start_at: int = 0,
                         end_at: List[int] = None,
                         model_name_prefix: str = "model",
                         model_type: str = 'lstm_attention') -> List[tuple]:
        """æ‰¹é‡å®éªŒ"""
        
        if end_at is None:
            end_at = []
        
        results = []
        
        for i, lookback in enumerate(lookbacks):
            max_steps = min(end_at[i], lookback) if i < len(end_at) else lookback
            
            j = 1
            while interval * j <= max_steps:
                steps = interval * j
                
                if steps < start_at:
                    j += 1
                    continue
                
                model_name = f"{str(lookback)}_{str(steps)}/{model_name_prefix}"
                
                try:
                    result = self.single_experiment(
                        lookback=lookback,
                        steps=steps,
                        model_name=model_name,
                        model_type=model_type,
                        append_params=False
                    )
                    results.append(result)
                    
                except Exception as e:
                    print(f"Error in experiment {model_name}: {e}")
                    continue
                
                finally:
                    j += 1
        
        return results
    
    def test_model(self, model_path: str, **kwargs):
        """æµ‹è¯•å·²è®­ç»ƒçš„æ¨¡å‹"""
        return self.model_tester.run_evaluation(model_path, **kwargs)


def select_model_file(folder_paths, max_depth=3):
    """
    åœ¨å¤šä¸ªæ–‡ä»¶å¤¹åŠå…¶å­ç›®å½•ä¸­æŸ¥æ‰¾.h5æˆ–.kerasæ–‡ä»¶ï¼ŒæŒ‰å­—æ¯é¡ºåºç¼–å·å¹¶è®©ç”¨æˆ·é€‰æ‹©
    
    å‚æ•°:
    folder_paths: å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ–‡ä»¶å¤¹è·¯å¾„
    max_depth: int, æœ€å¤§æ£€ç´¢æ·±åº¦ï¼ˆé»˜è®¤3å±‚ï¼‰
    
    è¿”å›:
    é€‰æ‹©çš„.h5æˆ–.kerasæ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    """
    if isinstance(folder_paths, str):
        folder_paths = [folder_paths]  # å•ä¸ªè·¯å¾„è½¬ä¸ºåˆ—è¡¨
    
    all_h5_files = []
    
    for folder_path in folder_paths:
        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(folder_path):
            raise FileNotFoundError(f"æ–‡ä»¶å¤¹è·¯å¾„ä¸å­˜åœ¨: {folder_path}")
        
        if not os.path.isdir(folder_path):
            raise NotADirectoryError(f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {folder_path}")

        base_depth = folder_path.rstrip(os.sep).count(os.sep)
        folder_name = os.path.basename(os.path.normpath(folder_path))

        # éå†æ–‡ä»¶å¤¹ï¼ˆé™åˆ¶æ·±åº¦ï¼‰
        for root, dirs, files in os.walk(folder_path):
            current_depth = root.count(os.sep) - base_depth
            if current_depth >= max_depth:
                dirs[:] = []  # ä¸å†æ·±å…¥
                continue
            for file in files:
                if file.endswith(".h5") or file.endswith(".keras"):
                    full_path = os.path.join(root, file)
                    relative_path = os.path.relpath(full_path, folder_path)
                    # åœ¨ç›¸å¯¹è·¯å¾„å‰åŠ ä¸Šé¡¶å±‚ç›®å½•åï¼Œé¿å…å†²çª
                    combined_relpath = os.path.join(folder_name, relative_path)
                    all_h5_files.append((combined_relpath, full_path))

    # æŒ‰ç›¸å¯¹è·¯å¾„æ’åº
    all_h5_files.sort(key=lambda x: x[0])
    
    if not all_h5_files:
        print(f"åœ¨ {folder_paths} åŠå…¶ {max_depth} å±‚å­ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°.h5æˆ–.kerasæ–‡ä»¶")
        return None
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    print(f"åœ¨ {folder_paths} åŠå…¶ {max_depth} å±‚å­ç›®å½•ä¸­æ‰¾åˆ° {len(all_h5_files)} ä¸ª.h5æˆ–.kerasæ–‡ä»¶:")
    print("-" * 50)
    
    for i, (rel_path, _) in enumerate(all_h5_files, 1):
        print(f"{i:2d}. {rel_path}")
    
    print("-" * 50)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    while True:
        try:
            choice = input("è¯·é€‰æ‹©æ–‡ä»¶ç¼–å· (è¾“å…¥qé€€å‡º): ").strip()
            
            if choice.lower() == 'q':
                print("ç”¨æˆ·é€‰æ‹©é€€å‡º")
                return None
            
            choice_num = int(choice)
            
            if 1 <= choice_num <= len(all_h5_files):
                rel_path, full_path = all_h5_files[choice_num - 1]
                print(f"å·²é€‰æ‹©: {rel_path}")
                return full_path
            else:
                print(f"è¯·è¾“å…¥ 1-{len(all_h5_files)} ä¹‹é—´çš„æ•°å­—")
                
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
            return None



def create_custom_config():
    """åˆ›å»ºè‡ªå®šä¹‰é…ç½®çš„ç¤ºä¾‹"""
    
    # æ•°æ®é…ç½® - ä½¿ç”¨ä¸åŒçš„scalerå’Œæ®‹å·®è®¾ç½®
    data_config = DataConfig(
        model_target_dir="models_refactored",
        dataset_path="eopc04_14_IAU2000.62-now.csv",
        train_ratio=0.75,
        val_ratio=0.15,
        residual_type='both',  # 'none', 'x', 'y', 'both'
        use_scaler=True,
        scaler_type='standard',  # 'minmax', 'standard', 'robust', 'none'
        scaler_after_residual=False,  # åœ¨æ®‹å·®å¤„ç†å‰è¿˜æ˜¯ååº”ç”¨scaler
        scaler_params={'feature_range': (0, 1)} if 'minmax' else {}
    )
    
    # æ¨¡å‹é…ç½®
    model_config = ModelConfig(
        model_target_dir= "data/models_reproduce/residual-mse",
        lstm0=64,
        lstm1=64,
        lstm2=32,
        attnhead=4,  # å¢åŠ æ³¨æ„åŠ›å¤´æ•°
        attndim=32,
        dropout0=0.2,
        dropout1=0.2,
        dropout2=0.1
    )
    
    # è®­ç»ƒé…ç½®
    training_config = TrainingConfig(
        learning_rate=1e-3,
        batch_size=32,
        epochs=100,
        early_stop=10,
        loss='mae-corr',
        corr_alpha=1e-3
    )
    
    return data_config, model_config, training_config


def train_main(lookback: List[int],
               steps: int,
               model_name: str,
               use_batch: bool,
               interval: int,
               start_at: int,
               end_at: int):
    """è®­ç»ƒä¸»å‡½æ•°"""
    
    # 1. ä½¿ç”¨é»˜è®¤é…ç½®
    print("Using default configuration...")
    runner_default = ExperimentRunner()

    # # 2. ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
    # print("Using custom configuration...")
    # data_config, model_config, training_config = create_custom_config()
    # runner_custom = ExperimentRunner(data_config, model_config, training_config)
    
    if use_batch:
        # æ‰¹é‡å®éªŒ
        results = runner_default.batch_experiments(
            lookbacks=lookback,
            interval=interval,
            start_at=start_at,
            end_at=[lookback[i] - end_at for i in range(len(lookback))] if end_at <= 0
            else [end_at for i in range(len(lookback))],
            model_name_prefix=model_name,
            model_type=MODEL_CONFIG.model_type
        )
    else:
        # å•ä¸ªå®éªŒ
        if len(lookback) > 1:
            print(f"only support single lookback when not batch mode, recieved {str(len(lookback))}")
        else:
            model, history, data_info = runner_default.single_experiment(
                lookback=lookback[0],
                steps=steps,
                model_name=model_name,
                model_type=MODEL_CONFIG.model_type
            )
    
    print("Main function completed.")

def test_main(model_path: str = None, data_index: int = -1):
    """æµ‹è¯•ä¸»å‡½æ•°"""
    # 1. ä½¿ç”¨é»˜è®¤é…ç½®
    print("Using default configuration...")
    runner_default = ExperimentRunner()
    # 2. æµ‹è¯•æ¨¡å‹
    if not model_path:
        model_path = select_model_file(runner_default.data_config.model_target_dir, max_depth=7)
        single_test = False
    else:
        single_test = True
    while model_path:
        if os.path.exists(model_path):
            print("Testing existing model...")
            test_results = runner_default.test_model(
                model_path=model_path,
                do_predict=[0, 0, 1],  # ä»…é¢„æµ‹æµ‹è¯•é›†
                print_summary=True
            )
            T_test = np.concatenate([test_results['data']['raw_data'][4], test_results['ground_truth']['test']], axis=1)
            p_test = np.concatenate([test_results['data']['raw_data'][4], test_results['predictions']['test']], axis=1)
            plot_pm(T_test, p_test, data_index)
        else:
            print(f"{model_path} doesn't exist!")
        if single_test:
            break
        else:
            model_path = select_model_file(runner_default.data_config.model_target_dir, max_depth=7)
    
    print("Main function completed.")

def val_main(repo_path: str, model_name: str, data_path: str):
    """è¯„ä¼°ä¸»å‡½æ•°"""
    if not Path(repo_path).exists():
        raise ValueError(f"æ ¹ç›®å½•ä¸å­˜åœ¨: {repo_path}")
    
    # è·å–åŸºç¡€è¯„ä¼°ç»“æœè¡¨
    data_manager = DataManager(repo_path, excel_filename=data_path)

    # é€æ¨¡å‹è¿›è¡Œè¯„ä¼°
    config_path = f"{repo_path}/config.json"
    data_cfg, model_cfg, training_cfg = load_config(config_path)
    tester = ModelTester(data_cfg)

    for model_info in data_manager.get_existing_model_paths_with_configs(model_name):
        model_path, lookback, steps = model_info
        print(f"\n æ­£åœ¨è¯„ä¼°æ¨¡å‹: {model_path}")

        result = tester.load_and_test_model(model_path, [0, 0, 1], False)
        metrics: dict = result['metrics']['test']

        # ç¡®è®¤ç›®æ ‡è¡Œ
        rows = data_manager.locate_row_by_keys("lookback", "steps", lookback, steps)
        if not rows:
            print(f" æœªæ‰¾åˆ° lookback={lookback}, steps={steps} çš„è¡Œï¼Œè·³è¿‡ã€‚")
            continue
        row_idx = rows[0]

        # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œæ•´å†™è¿‡æ•°æ®ï¼ˆå³æ‰€æœ‰æŒ‡æ ‡åˆ—éƒ½éç©ºï¼‰
        already_complete = True
        for name, content in metrics.items():
            for metric_name in content.keys():
                col_name = f"{name}_{metric_name}"
                if col_name not in data_manager.get_all_headers():
                    already_complete = False
                    break
                val = data_manager.get_row_data(row_idx)[data_manager.header_map[col_name]-1]
                if val is None:
                    already_complete = False
                    break
            if not already_complete:
                break
        if already_complete:
            print(f" è¡Œ lookback={lookback}, steps={steps} å·²å­˜åœ¨å®Œæ•´æŒ‡æ ‡ï¼Œè·³è¿‡ã€‚")
            continue

        # å†™å…¥æŒ‡æ ‡
        for name, content in metrics.items():
            for metric_name, value in content.items():
                col_name = f"{name}_{metric_name}"
                # å¦‚æœåˆ—ä¸å­˜åœ¨ â†’ æ–°å¢
                if col_name not in data_manager.get_all_headers():
                    data_manager.add_empty_column(col_name)
                # å†™å€¼
                data_manager.modify_cell_by_keys(
                    "lookback", "steps", lookback, steps, 
                    col_name, float(value), limit_one=True
                )
        print(f" å†™å…¥å®Œæˆ: lookback={lookback}, steps={steps}")

    # ä¿å­˜Excel
    data_manager.save()
    print(f"\n å·²ä¿å­˜è¯„ä¼°ç»“æœè‡³ {data_manager.get_excel_path()}")

def plot_main(repo_path: str, data_path: str):
    """ç»˜å›¾ä¸»å‡½æ•°"""
    data = DataManager(repo_path, excel_filename=data_path)
    plot_grid_graph(data.get_column_data('lookback'),
                    data.get_column_data('steps'),
                    data.get_column_data('overall_pcc'),
                    title='',
                    metric_name='Corrcoef',
                    unit='',
                    scale=1.0,
                    figsize=(16, 8),
                    reverse_colorbar_num=False,
                    reverse_colorbar_color=True,
                    cmap='viridis',
                    font_size=28,
                    vrange=(0.701, 0.999))
    
def predict_main(model_path: str, csv_path: str, 
                 save_path: str = None):
    """
    ä¸»é¢„æµ‹å‡½æ•°ï¼šåŠ è½½æ¨¡å‹ã€è¯»å–CSVæœ€æ–°åºåˆ—ã€è¿›è¡Œé¢„æµ‹å¹¶å†™å…¥ç»“æœã€‚

    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.keras / .h5)
        csv_path: è¦é¢„æµ‹çš„CSVæ–‡ä»¶è·¯å¾„
        train_csv_path: å¯é€‰ï¼Œç”¨äºæ‹ŸåˆScalerçš„è®­ç»ƒæ•°æ®è·¯å¾„
        save_path: å¯é€‰ï¼Œé¢„æµ‹ç»“æœä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤è¦†ç›–åŸCSVï¼‰
    """

    print("=" * 60)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ predict_main()")
    print("=" * 60)

    # === 1ï¸âƒ£ åŠ è½½CSVæ•°æ® ===
    csv_manager = CSVDataManager(csv_path)
    csv_manager.print_summary()

    # === 2ï¸âƒ£ åˆ›å»ºæ¨¡å‹è¿è¡Œå™¨ ===
    # âš ï¸ æ³¨æ„ï¼šDataConfig å¿…é¡»ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼
    data_config, _, _ = load_config("config_base.json")

    runner = ModelRunner(model_path, data_config)

    # === 3ï¸âƒ£ è·å–æœ€æ–°lookbackåºåˆ— ===
    lookback = runner.lookback
    steps = runner.steps

    START_MJD = 51544
    print(f"è¯»å–ï¼ˆä¸ä¸€å®šï¼‰æœ€æ–° {lookback} æ¡è®°å½•ä½œä¸ºè¾“å…¥åºåˆ—...")
    # input_seq = csv_manager.read_latest_sequence(
    #     length=lookback
    # )
    input_seq = csv_manager.read_sequence_by_mjd(
        start_mjd=START_MJD - 1200,
        length=lookback
    )
    print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {input_seq.shape}")

    # === 4ï¸âƒ£ æ‹ŸåˆScaler ===
    runner.fit_scaler_from_data()

    # === 5ï¸âƒ£ æ¨¡å‹é¢„æµ‹ ===
    print(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹é¢„æµ‹æœªæ¥ {steps} æ­¥...")
    predictions = runner.predict(input_seq)
    print(f"âœ… é¢„æµ‹å®Œæˆ: ç»“æœå½¢çŠ¶ = {predictions.shape}")

    # === 6ï¸âƒ£ å†™å…¥é¢„æµ‹ç»“æœ ===
    print("æ­£åœ¨å°†é¢„æµ‹ç»“æœå†™å…¥CSV...")
    # csv_manager.append_predictions_from_last(predictions, save_path=save_path)
    csv_manager.write_predictions(predictions=predictions, 
                                  start_date=START_MJD)
    print("âœ… CSVå†™å…¥å®Œæˆ")

    print("=" * 60)
    print("ğŸ¯ é¢„æµ‹æµç¨‹å·²ç»“æŸ")
    print("=" * 60)

def draw_main(csv_path: str):
    """é¢„æµ‹æ•°æ®ç»˜åˆ¶å‡½æ•°"""
    # ===åŠ è½½CSVæ•°æ® ===
    csv_manager = CSVDataManager(csv_path)
    csv_manager.print_summary()

    # history_data = csv_manager.read_predictions_by_date_range('x_pole', 'y_pole',
    #                                                           '2023-7-9', '2025-9-15')
    history_data = csv_manager.read_predictions_by_date_range('x_pole', 'y_pole',
                                                              '1997-1-1', '1999-12-31')

    # bullitenA_data = csv_manager.read_predictions_by_date_range('a_x_pole_predict','a_y_pole_predict',
    #                                                             '2025-9-16', '2026-9-11')
    bullitenA_data = csv_manager.read_predictions_by_date_range('x_pole','y_pole',
                                                                '2000-1-1', '2003-1-4')
    
    # our_data = csv_manager.read_predictions_by_date_range('x_pole_predict','y_pole_predict',
    #                                                             '2025-9-16', '2027-5-8')
    our_data = csv_manager.read_predictions_by_date_range('x_pole_predict','y_pole_predict',
                                                                '2000-1-1', '2003-1-4')
    
    # plot_pm(bullitenA_data, our_data, start_date='2025-9-16')
    # plot_pm_with_history(history_data, bullitenA_data, our_data,
    #                      '2025-9-16',
    #                      legend_labels=('history', 'BulletinA', 'Our Model'))
    fig = plot_pm_with_history(history_data, bullitenA_data, our_data,
                         '2000-1-1',
                         legend_labels=('history', 'true data', 'Our Model'))
    
    
    # === è‡ªåŠ¨åˆ›å»ºç›®å½•å¹¶ä¿å­˜ ===
    save_path: str = "figures/compare.png"
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    fig.savefig(save_path, dpi=300)

    # è¿”å› Figure ä»¥ä¾¿å¤–éƒ¨ç»§ç»­æ“ä½œï¼ˆå¦‚ plt.show æˆ–å†ä¿å­˜ï¼‰

    pass

def cal_draw_mae(model_paths: str = None, 
                 labels: List[str] = None,
                 config_path: str = None,
                 save_fig: bool = True,
                 mode: str = 'run',
                 data_path: str = None):
    """
    è®¡ç®—å¹¶ç»˜åˆ¶ MAE(å¹³å‡ç»å¯¹è¯¯å·®)
    
    :param model_paths: æ¨¡å‹è·¯å¾„åˆ—è¡¨,é»˜è®¤ä¸º None(å°†å¼¹å‡ºé€‰æ‹©ç•Œé¢)
    :param labels: æ ‡ç­¾åˆ—è¡¨
    :param config_path: é…ç½®æ–‡ä»¶è·¯å¾„,é»˜è®¤ä¸ºNone
    :param save_fig: æ˜¯å¦ä¿å­˜å›¾åƒ,é»˜è®¤ä¸º True
    :param mode: è¿è¡Œæ¨¡å¼, 'run' = è¿è¡Œæ¨¡å‹å¹¶ä¿å­˜æ•°æ®, 'load' = è¯»å–å·²æœ‰æ•°æ®
    :param data_path: æ•°æ®æ–‡ä»¶è·¯å¾„,é»˜è®¤ä¸º 'data/mae_results.json' (æ”¯æŒ .json æˆ– .pkl)
    """
    
    print("=" * 60)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ cal_draw_mae()")
    print("=" * 60)
    
    # è®¾ç½®é»˜è®¤æ•°æ®è·¯å¾„
    if data_path is None:
        data_path = 'data/mae_results.json'
    
    # åˆ¤æ–­æ–‡ä»¶æ ¼å¼
    is_json = data_path.endswith('.json')
    is_pickle = data_path.endswith('.pkl') or data_path.endswith('.pickle')
    
    # === æ¨¡å¼é€‰æ‹© ===
    if mode == 'load':
        # è¯»å–æ¨¡å¼
        print(f"ğŸ“‚ è¯»å–æ¨¡å¼: ä» {data_path} åŠ è½½æ•°æ®...")
        
        if not os.path.exists(data_path):
            print(f"âŒ é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return
        
        try:
            if is_json:
                # JSON æ ¼å¼
                with open(data_path, 'r', encoding='utf-8') as f:
                    saved_data = json.load(f)
                
                # å°†åˆ—è¡¨è½¬æ¢å› numpy æ•°ç»„
                maes_dict = {
                    label: np.array(values) 
                    for label, values in saved_data['maes_dict'].items()
                }
                labels = saved_data['labels']
                
            elif is_pickle:
                # Pickle æ ¼å¼
                with open(data_path, 'rb') as f:
                    saved_data = pickle.load(f)
                
                maes_dict = saved_data['maes_dict']
                labels = saved_data['labels']
            
            else:
                print(f"âŒ é”™è¯¯: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼,è¯·ä½¿ç”¨ .json æˆ– .pkl")
                return
            
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®")
            print(f"   æ¨¡å‹æ•°é‡: {len(maes_dict)}")
            print(f"   æ ‡ç­¾: {labels}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return
    
    elif mode == 'run':
        # è¿è¡Œæ¨¡å¼
        print("ğŸƒ è¿è¡Œæ¨¡å¼: æ‰§è¡Œæ¨¡å‹æ¨ç†...")
        
        # === 1ï¸âƒ£ é€‰æ‹©æˆ–æŒ‡å®šæ¨¡å‹è·¯å¾„ ===
        if config_path:
            data_cfg, model_cfg, training_cfg = load_config(config_path)
            runner_default = ExperimentRunner(data_config=data_cfg, model_config=model_cfg, training_config=training_cfg)
        else:
            runner_default = ExperimentRunner()
        
        if not model_paths:
            # äº¤äº’å¼é€‰æ‹©å•ä¸ªæ¨¡å‹
            model_path = select_model_file(
                runner_default.data_config.model_target_dir, 
                max_depth=7
            )
            if not model_path:
                print("âŒ æœªé€‰æ‹©æ¨¡å‹")
                return
            model_paths = [model_path]
        
        # éªŒè¯æ‰€æœ‰æ¨¡å‹è·¯å¾„
        valid_model_paths = []
        for path in model_paths:
            if os.path.exists(path):
                valid_model_paths.append(path)
            else:
                print(f"âš ï¸  è­¦å‘Š: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨,å·²è·³è¿‡: {path}")
        
        if not valid_model_paths:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å‹è·¯å¾„")
            return
        
        print(f"ğŸ“ å°†å¤„ç† {len(valid_model_paths)} ä¸ªæ¨¡å‹")
        
        # === 2ï¸âƒ£ å¤„ç†æ ‡ç­¾åˆ—è¡¨ ===
        if labels is None:
            # ä½¿ç”¨æ¨¡å‹æ–‡ä»¶åä½œä¸ºæ ‡ç­¾
            labels = [os.path.basename(path).replace('.keras', '').replace('.h5', '') 
                      for path in valid_model_paths]
        elif len(labels) != len(valid_model_paths):
            print(f"âš ï¸  è­¦å‘Š: æ ‡ç­¾æ•°é‡({len(labels)})ä¸æ¨¡å‹æ•°é‡({len(valid_model_paths)})ä¸åŒ¹é…,ä½¿ç”¨é»˜è®¤æ ‡ç­¾")
            labels = [os.path.basename(path).replace('.keras', '').replace('.h5', '') 
                      for path in valid_model_paths]
        
        # === 3ï¸âƒ£ å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œæ¨ç†å’ŒMAEè®¡ç®— ===
        maes_dict = {}
        
        for idx, (model_path, label) in enumerate(zip(valid_model_paths, labels)):
            print(f"\n{'='*60}")
            print(f"ğŸ“Š å¤„ç†æ¨¡å‹ [{idx+1}/{len(valid_model_paths)}]: {label}")
            print(f"   è·¯å¾„: {model_path}")
            print(f"{'='*60}")
            
            # æµ‹è¯•æ¨¡å‹å¹¶è·å–é¢„æµ‹ç»“æœ
            print("ğŸ”„ æ­£åœ¨è¿›è¡Œæ¨¡å‹æ¨ç†...")
            test_results = runner_default.test_model(
                model_path=model_path,
                do_predict=[0, 0, 1],  # ä»…é¢„æµ‹æµ‹è¯•é›†
                print_summary=True
            )
            
            # æå–å®é™…å€¼å’Œé¢„æµ‹å€¼
            actual = test_results['ground_truth']['test']  # å½¢çŠ¶: (batchsize, steps, 2)
            predicted = test_results['predictions']['test']  # å½¢çŠ¶: (batchsize, steps, 2)
            
            print(f"âœ… æ¨ç†å®Œæˆ")
            print(f"   å®é™…å€¼å½¢çŠ¶: {actual.shape}")
            print(f"   é¢„æµ‹å€¼å½¢çŠ¶: {predicted.shape}")
            
            # è®¡ç®—MAE
            print("ğŸ“Š è®¡ç®—æ¯æ­¥MAE...")
            mae_by_step = calculate_mae_by_step(actual, predicted)
            dataset_mae = calculate_mae_of_dataset(mae_by_step)
            
            # ä¿å­˜åˆ°å­—å…¸
            maes_dict[label] = dataset_mae
            
            # æ‰“å°è¯¦ç»†çš„MAEç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“ˆ MAEç»Ÿè®¡ä¿¡æ¯ ({label}):")
            print(f"   PMX - æœ€å°MAE: {dataset_mae[:, 0].min():.4f} mas")
            print(f"   PMX - æœ€å¤§MAE: {dataset_mae[:, 0].max():.4f} mas")
            print(f"   PMX - å¹³å‡MAE: {dataset_mae[:, 0].mean():.4f} mas")
            print(f"   PMY - æœ€å°MAE: {dataset_mae[:, 1].min():.4f} mas")
            print(f"   PMY - æœ€å¤§MAE: {dataset_mae[:, 1].max():.4f} mas")
            print(f"   PMY - å¹³å‡MAE: {dataset_mae[:, 1].mean():.4f} mas")
        
        # === ä¿å­˜è®¡ç®—ç»“æœ ===
        print("\n" + "=" * 60)
        print(f"ğŸ’¾ ä¿å­˜MAEæ•°æ®åˆ°: {data_path}")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(data_path), exist_ok=True)
        
        try:
            if is_json:
                # JSON æ ¼å¼ - éœ€è¦å°† numpy æ•°ç»„è½¬ä¸ºåˆ—è¡¨
                saved_data = {
                    'maes_dict': {
                        label: mae_values.tolist() 
                        for label, mae_values in maes_dict.items()
                    },
                    'labels': labels,
                    'model_paths': valid_model_paths
                }
                
                with open(data_path, 'w', encoding='utf-8') as f:
                    json.dump(saved_data, f, indent=2, ensure_ascii=False)
                
                print(f"âœ… æ•°æ®å·²ä¿å­˜ä¸º JSON æ ¼å¼")
                
            elif is_pickle:
                # Pickle æ ¼å¼ - å¯ä»¥ç›´æ¥ä¿å­˜ numpy æ•°ç»„
                saved_data = {
                    'maes_dict': maes_dict,
                    'labels': labels,
                    'model_paths': valid_model_paths
                }
                
                with open(data_path, 'wb') as f:
                    pickle.dump(saved_data, f)
                
                print(f"âœ… æ•°æ®å·²ä¿å­˜ä¸º Pickle æ ¼å¼")
            
            else:
                print(f"âš ï¸  è­¦å‘Š: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼,ä½¿ç”¨é»˜è®¤ JSON æ ¼å¼ä¿å­˜")
                data_path = data_path.rsplit('.', 1)[0] + '.json'
                
                saved_data = {
                    'maes_dict': {
                        label: mae_values.tolist() 
                        for label, mae_values in maes_dict.items()
                    },
                    'labels': labels,
                    'model_paths': valid_model_paths
                }
                
                with open(data_path, 'w', encoding='utf-8') as f:
                    json.dump(saved_data, f, indent=2, ensure_ascii=False)
                
                print(f"âœ… æ•°æ®å·²ä¿å­˜ä¸º JSON æ ¼å¼è‡³: {data_path}")
            
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Š: ä¿å­˜æ•°æ®å¤±è´¥: {e}")
    
    else:
        print(f"âŒ é”™è¯¯: æ— æ•ˆçš„æ¨¡å¼ '{mode}', è¯·ä½¿ç”¨ 'run' æˆ– 'load'")
        return
    
    # === 4ï¸âƒ£ ç»Ÿä¸€ç»˜åˆ¶æ‰€æœ‰æ¨¡å‹çš„MAEæ›²çº¿ ===
    print("\n" + "=" * 60)
    print("ğŸ¨ ç»˜åˆ¶æ‰€æœ‰æ¨¡å‹çš„MAEå¯¹æ¯”æ›²çº¿...")
    print("=" * 60)
    
    plot_mae_by_step(
        maes_dict,
        strlist=labels,  # æŒ‰ç…§è¾“å…¥é¡ºåºæ˜¾ç¤ºå›¾ä¾‹
        shape=(7, 5)
    )
    
    # === 5ï¸âƒ£ ä¿å­˜å›¾åƒ(å¯é€‰)===
    if save_fig:
        # ç”ŸæˆåŒ…å«æ‰€æœ‰æ¨¡å‹åç§°çš„æ–‡ä»¶å
        if len(labels) == 1:
            save_name = f"mae_{labels[0]}"
        else:
            save_name = f"mae_comparison_{len(labels)}models"
        
        save_path = f"figures/{save_name}.png"
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ å›¾åƒå·²ä¿å­˜è‡³: {save_path}")
    
    print("\n" + "=" * 60)
    print("ğŸ¯ MAEè®¡ç®—å’Œç»˜åˆ¶æµç¨‹å·²å®Œæˆ")
    print(f"   å…±å¤„ç† {len(maes_dict)} ä¸ªæ¨¡å‹")
    print("=" * 60)
    
    return maes_dict  # è¿”å›ç»“æœä¾›è¿›ä¸€æ­¥ä½¿ç”¨

# åœ¨ __main__ ä¸­æ·»åŠ è°ƒç”¨
if __name__ == "__main__":
    # åˆ›å»ºè§£æå™¨
    parser = argparse.ArgumentParser(description='æ¨¡å‹è®­ç»ƒ/æµ‹è¯•è„šæœ¬')
    # æ·»åŠ å‚æ•°
    parser.add_argument('action', help='train or test or val or plot or predict or draw or mae')
    
    # æµ‹è¯•å‚æ•° - ä¿®æ”¹ä¸ºæ¥æ”¶å¤šä¸ªå€¼
    parser.add_argument('--path', type=str, nargs='+', help='test model path(s)', default=None)
    parser.add_argument('--index', type=int, help='test data index', default=-1)
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--lookback', type=int, nargs='+', help='train lookback (int or list of int)', default=[200])
    parser.add_argument('--steps', type=int, help='train steps', default=100)
    parser.add_argument('--name', type=str, help='train model name', default='model')
    parser.add_argument('--batch', action='store_true', help='train model with batch', default=False)
    parser.add_argument('--interval', type=int, help='batch steps interval', default=100)
    parser.add_argument('--startstep', type=int, help='batch steps start', default=0)
    parser.add_argument('--endstep', type=int, help='batch steps end', default=0)
    
    # è¯„ä¼°å’Œç»˜åˆ¶ç»“æœå›¾å‚æ•°
    parser.add_argument('--repopath', type=str, help='repo to evaluate', default='')
    parser.add_argument('--modelname', type=str, help='model name to scan', default='')
    parser.add_argument('--dataname', type=str, help='xlsx file name', default='evaluation')
    
    # é¢„æµ‹å‚æ•°
    parser.add_argument('--modelpath', type=str, help='prediction model path', default='')
    parser.add_argument('--csvpath', type=str, help='csv data path', default='')
    
    # MAEç»˜åˆ¶å‚æ•° - ä¿®æ”¹æ ‡ç­¾å‚æ•°ä¸ºæ¥æ”¶å¤šä¸ªå€¼
    parser.add_argument('--savefig', action='store_true', help='save mae figure', default=False)
    parser.add_argument('--labels', type=str, nargs='+', help='labels for each model in the plot', default=None)
    parser.add_argument('--maemode', type=str,  help='save to or load from data path, "load" or "run"', default='run')
    parser.add_argument('--maedatapath', type=str,  help='mae save load data path, "load" or "run"', default='data/predicts/mae_figure_data.json')
    
    # é…ç½®å‚æ•°
    parser.add_argument('--cfgpath', type=str, help='config relative full name', default=None)
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    if args.action == "train":
        # è¿è¡Œè®­ç»ƒä¸»ç¨‹åº
        train_main(lookback=args.lookback,
                   steps=args.steps,
                   model_name=args.name,
                   use_batch=args.batch,
                   interval=args.interval,
                   start_at=args.startstep,
                   end_at=args.endstep)
    elif args.action == "test":
        # è¿è¡Œæµ‹è¯•ä¸»ç¨‹åº
        test_main(model_path=args.path,
                  data_index=args.index)
    elif args.action == "val":
        # è¿è¡Œæ¨¡å‹è¯„ä¼°ç¨‹åº
        val_main(repo_path=args.repopath,
                 model_name=args.modelname,
                 data_path=args.dataname)
    elif args.action == "plot":
        plot_main(repo_path=args.repopath,
                  data_path=args.dataname)
    elif args.action == "predict":
        predict_main(model_path=args.modelpath,
                     csv_path=args.csvpath)
    elif args.action == "draw":
        draw_main(csv_path=args.csvpath)
    elif args.action == "mae":
        # è¿è¡ŒMAEè®¡ç®—å’Œç»˜åˆ¶ç¨‹åº
        cal_draw_mae(model_paths=args.path,
                     labels=args.labels,
                     config_path=args.cfgpath,
                     save_fig=args.savefig,
                     mode=args.maemode,
                     data_path=args.maedatapath)

"""
æœ€ç»ˆæ–‡ç« ç”¨æ¨¡å‹ï¼š
mae2
mse2
mse-corr3
mse-int3
"""
